{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to TensorFlow\n",
    "\n",
    "> Linear Regression with TensorFlow\n",
    "\n",
    "郭耀仁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 大綱\n",
    "\n",
    "- 取得資料\n",
    "- 建構 TensorFlow 計算圖形\n",
    "- 訓練\n",
    "- 檢視 TensorBoard\n",
    "- 加入 Name Scopes\n",
    "- 隨堂練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 取得資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 簡單、作為測試目的即可\n",
    "\n",
    "Scikit-Learn Boston 房價資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "print(boston.feature_names)\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 1)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X_arr = boston.data[:, -1].reshape(-1, 1)\n",
    "y_arr = boston.target\n",
    "print(X_arr.shape)\n",
    "print(y_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 1)\n",
      "(152, 1)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 建構 TensorFlow 計算圖形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 準備 Placeholders 供訓練時輸入 X_train、y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X = tf.placeholder(tf.float32, X_train_shape)\n",
    "y = tf.placeholder(tf.float32, y_train_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 準備變數供訓練時尋找最適係數（Weights）與殘差項（Bias）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kuoyaojen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[[-1.0975873]]\n",
      "[0.79843736]\n"
     ]
    }
   ],
   "source": [
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "W = tf.Variable(tf.random_normal(W_shape))\n",
    "b = tf.Variable(tf.random_normal(b_shape))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 檢查 X、W 與 b 的外觀，寫下 y_pred 的公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 1)\n",
      "(1, 1)\n",
      "(1,)\n",
      "(354, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = tf.add(tf.matmul(X, W), b)\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "print(b.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(354, 1), dtype=float32)\n",
      "Tensor(\"Placeholder:0\", shape=(354, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 寫下成本函數的公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 宣告學習速率與 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 建構 TensorFlow 計算圖形完整程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, X_train_shape)\n",
    "y = tf.placeholder(tf.float32, y_train_shape)\n",
    "# variables\n",
    "W = tf.Variable(tf.random_normal(W_shape))\n",
    "b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 111882688.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument 111882690.0 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3566\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3567\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a float32 into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-738fbfabb513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         }\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch {}, loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    302\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    303\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    305\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument 111882690.0 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 發生了什麼事情？\n",
    "\n",
    "```python\n",
    "for i in range(n_steps):\n",
    "    # ...\n",
    "    # 這邊的物件命名同樣為 loss，但型別已經不同，feed_dict 是張量，但 fetch 是 ndarray\n",
    "    _, loss = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 修改物件命名之後再來試一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, X_train_shape)\n",
    "y = tf.placeholder(tf.float32, y_train_shape)\n",
    "# variables\n",
    "W = tf.Variable(tf.random_normal(W_shape))\n",
    "b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 34374416.0\n",
      "epoch 100, loss: nan\n",
      "epoch 200, loss: nan\n",
      "epoch 300, loss: nan\n",
      "epoch 400, loss: nan\n",
      "epoch 500, loss: nan\n",
      "epoch 600, loss: nan\n",
      "epoch 700, loss: nan\n",
      "epoch 800, loss: nan\n",
      "epoch 900, loss: nan\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 為什麼 loss 都是 nan？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning Rate 太大的緣故\n",
    "\n",
    "![](img/0406.jpeg)\n",
    "\n",
    "Source: [Machine Learning | Coursera](https://www.coursera.org/learn/machine-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 降低 Learning Rate 之後再來試一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.00000001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, X_train_shape)\n",
    "y = tf.placeholder(tf.float32, y_train_shape)\n",
    "# variables\n",
    "W = tf.Variable(tf.random_normal(W_shape))\n",
    "b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 86089632.0\n",
      "epoch 100, loss: 24685726.0\n",
      "epoch 200, loss: 23067824.0\n",
      "epoch 300, loss: 21637766.0\n",
      "epoch 400, loss: 20373738.0\n",
      "epoch 500, loss: 19256460.0\n",
      "epoch 600, loss: 18268904.0\n",
      "epoch 700, loss: 17396008.0\n",
      "epoch 800, loss: 16624453.0\n",
      "epoch 900, loss: 15942473.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 檢視 TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 回到 Terminal 啟動 TensorBoard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=path/to/log-directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/0407.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 加入 Name Scopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## TensorFlow 不知道哪些節點應該歸類在一起\n",
    "\n",
    "利用 `with tf.name_scope(name_of_that_scope)` 將節點歸類起來，讓 Graph 更簡潔\n",
    "\n",
    "```python\n",
    "with tf.name_scope(name_of_that_scope):\n",
    "  # declare op_1\n",
    "  # declare op_2\n",
    "  # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.00000001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    X = tf.placeholder(tf.float32, X_train_shape)\n",
    "    y = tf.placeholder(tf.float32, y_train_shape)\n",
    "# variables\n",
    "with tf.name_scope(\"variables\"):\n",
    "    W = tf.Variable(tf.random_normal(W_shape))\n",
    "    b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 29167918.0\n",
      "epoch 100, loss: 25331188.0\n",
      "epoch 200, loss: 23638348.0\n",
      "epoch 300, loss: 22142048.0\n",
      "epoch 400, loss: 20819474.0\n",
      "epoch 500, loss: 19650446.0\n",
      "epoch 600, loss: 18617148.0\n",
      "epoch 700, loss: 17703820.0\n",
      "epoch 800, loss: 16896524.0\n",
      "epoch 900, loss: 16182963.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph with name scopes\n",
    "\n",
    "![](img/0408.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 調整訓練的次數與觀察 loss 是否漸趨收斂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 46752384.0\n",
      "step 500, loss: 17639456.0\n",
      "step 1000, loss: 14467258.0\n",
      "step 1500, loss: 12755778.0\n",
      "step 2000, loss: 11832389.0\n",
      "step 2500, loss: 11334192.0\n",
      "step 3000, loss: 11065409.0\n",
      "step 3500, loss: 10920393.0\n",
      "step 4000, loss: 10842154.0\n",
      "step 4500, loss: 10799942.0\n",
      "step 5000, loss: 10777167.0\n",
      "step 5500, loss: 10764880.0\n",
      "step 6000, loss: 10758249.0\n",
      "step 6500, loss: 10754673.0\n",
      "step 7000, loss: 10752742.0\n",
      "step 7500, loss: 10751702.0\n",
      "step 8000, loss: 10751142.0\n",
      "step 8500, loss: 10750837.0\n",
      "step 9000, loss: 10750672.0\n",
      "step 9500, loss: 10750586.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "loss_history = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        loss_history.append(loss_)\n",
    "        if i % 500 == 0:\n",
    "            print(\"step {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), loss_history)\n",
    "plt.title(\"Loss Summary\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025418748\n",
      "22.719406\n",
      "10750538.0\n"
     ]
    }
   ],
   "source": [
    "mse = loss_history[-1]\n",
    "print(w_final[0, 0])\n",
    "print(b_final[0])\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 加入 Batch 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kuoyaojen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.00000001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    X = tf.placeholder(tf.float32) # 不要指定外觀\n",
    "    y = tf.placeholder(tf.float32) # 不要指定外觀\n",
    "# variables\n",
    "with tf.name_scope(\"variables\"):\n",
    "    W = tf.Variable(tf.random_normal(W_shape))\n",
    "    b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 22322.10546875\n",
      "epoch 500, loss: 1936.48291015625\n",
      "epoch 1000, loss: 1824.188232421875\n",
      "epoch 1500, loss: 1721.90625\n",
      "epoch 2000, loss: 1628.781982421875\n",
      "epoch 2500, loss: 1544.02880859375\n",
      "epoch 3000, loss: 1466.93212890625\n",
      "epoch 3500, loss: 1396.821044921875\n",
      "epoch 4000, loss: 1333.09521484375\n",
      "epoch 4500, loss: 1275.19921875\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "loss_history = []\n",
    "batch_size = 50\n",
    "n_obs = X_train.shape[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        pos = 0\n",
    "        while pos < n_obs:\n",
    "            batch_X = X_train[pos:(pos + batch_size)]\n",
    "            batch_y = y_train[pos:(pos + batch_size)]\n",
    "            feed_dict = {\n",
    "                X: batch_X,\n",
    "                y: batch_y\n",
    "            }\n",
    "            _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "            pos += batch_size\n",
    "        loss_history.append(loss_)\n",
    "        if i % 500 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 將 Loss 加入 TensorBoard 中的 Scalar 頁籤\n",
    "\n",
    "- 增加一個 summaries 的 name scope\n",
    "- 每一次的 epoch都要將 loss 記錄起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.00000001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    X = tf.placeholder(tf.float32, X_train_shape)\n",
    "    y = tf.placeholder(tf.float32, y_train_shape)\n",
    "# variables\n",
    "with tf.name_scope(\"variables\"):\n",
    "    W = tf.Variable(tf.random_normal(W_shape))\n",
    "    b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    y_pred = tf.matmul(X, W) + b\n",
    "# loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)\n",
    "# summaries\n",
    "with tf.name_scope(\"summary\"):\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 29187020.0\n",
      "epoch 500, loss: 19634076.0\n",
      "epoch 1000, loss: 15543408.0\n",
      "epoch 1500, loss: 13336389.0\n",
      "epoch 2000, loss: 12145644.0\n",
      "epoch 2500, loss: 11503200.0\n",
      "epoch 3000, loss: 11156594.0\n",
      "epoch 3500, loss: 10969591.0\n",
      "epoch 4000, loss: 10868699.0\n",
      "epoch 4500, loss: 10814261.0\n",
      "epoch 5000, loss: 10784892.0\n",
      "epoch 5500, loss: 10769048.0\n",
      "epoch 6000, loss: 10760500.0\n",
      "epoch 6500, loss: 10755886.0\n",
      "epoch 7000, loss: 10753398.0\n",
      "epoch 7500, loss: 10752055.0\n",
      "epoch 8000, loss: 10751330.0\n",
      "epoch 8500, loss: 10750940.0\n",
      "epoch 9000, loss: 10750729.0\n",
      "epoch 9500, loss: 10750615.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "loss_history = []\n",
    "train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)  \n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss_, summary = sess.run([optimizer, loss, merged], feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, i)\n",
    "        if i % 500 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](img/0409.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 如果 Loss Function 沒有收斂怎麼辦？\n",
    "\n",
    "- 增加 Steps\n",
    "- 增加 Learning rate\n",
    "- 更換 Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 如果重新訓練的時候產生了錯誤呢？\n",
    "\n",
    "- Restart Kernel 清空 Graph\n",
    "- 或者在訓練之前執行：\n",
    "\n",
    "```python\n",
    "tf.reset_default_graph()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 隨堂練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 以 Boston 建立一個複迴歸模型：MEDV ~ RM + AGE + LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 3)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X_arr = boston.data[:, [4, 5, -1]]\n",
    "y_arr = boston.target\n",
    "print(X_arr.shape)\n",
    "print(y_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 3)\n",
      "(152, 3)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.00000001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    X = tf.placeholder(tf.float32, X_train_shape)\n",
    "    y = tf.placeholder(tf.float32, y_train_shape)\n",
    "# variables\n",
    "with tf.name_scope(\"variables\"):\n",
    "    W = tf.Variable(tf.random_normal(W_shape))\n",
    "    b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 110289008.0\n",
      "epoch 100, loss: 11151406.0\n",
      "epoch 200, loss: 11140889.0\n",
      "epoch 300, loss: 11139606.0\n",
      "epoch 400, loss: 11138359.0\n",
      "epoch 500, loss: 11137118.0\n",
      "epoch 600, loss: 11135880.0\n",
      "epoch 700, loss: 11134644.0\n",
      "epoch 800, loss: 11133415.0\n",
      "epoch 900, loss: 11132190.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "loss_history = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        feed_dict = {\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "        _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        loss_history.append(loss_)\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), loss_history)\n",
    "plt.title(\"Loss Summary\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mse = loss_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6226004 ]\n",
      " [3.0774918 ]\n",
      " [0.21202205]]\n",
      "[0.18505369]\n",
      "11130982.0\n"
     ]
    }
   ],
   "source": [
    "print(w_final)\n",
    "print(b_final)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 以 Kaggle House Prices 建立一個複迴歸模型：SalePrice ~ OverallQual + GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sample_submission.csv to /Users/kuoyaojen/intro-to-tensorflow\n",
      "  0%|                                               | 0.00/31.2k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 31.2k/31.2k [00:00<00:00, 1.45MB/s]\n",
      "Downloading test.csv to /Users/kuoyaojen/intro-to-tensorflow\n",
      "100%|████████████████████████████████████████| 441k/441k [00:00<00:00, 1.14MB/s]\n",
      "\n",
      "Downloading train.csv to /Users/kuoyaojen/intro-to-tensorflow\n",
      "100%|████████████████████████████████████████| 450k/450k [00:00<00:00, 1.50MB/s]\n",
      "\n",
      "Downloading data_description.txt to /Users/kuoyaojen/intro-to-tensorflow\n",
      "  0%|                                               | 0.00/13.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 13.1k/13.1k [00:00<00:00, 5.46MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c house-prices-advanced-regression-techniques --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "X_arr = train.loc[:, [\"OverallQual\", \"GrLivArea\"]].values\n",
    "y_arr = train[\"SalePrice\"].values.reshape(-1, 1)\n",
    "scalerX = StandardScaler().fit(X_arr)\n",
    "scalery = StandardScaler().fit(y_arr)\n",
    "X_arr_scaled = scalerX.transform(X_arr)\n",
    "y_arr_scaled = scalery.transform(y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 2)\n",
      "(438, 2)\n",
      "(1022, 1)\n",
      "(438, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr_scaled, y_arr_scaled, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "W_shape = (X_train_shape[1], 1)\n",
    "b_shape = (1,)\n",
    "alpha = 0.00001\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "\n",
    "# placeholders\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    X = tf.placeholder(tf.float32) # 不指定外觀\n",
    "    y = tf.placeholder(tf.float32) # 不指定外觀\n",
    "# variables\n",
    "with tf.name_scope(\"variables\"):\n",
    "    W = tf.Variable(tf.random_normal(W_shape))\n",
    "    b = tf.Variable(tf.random_normal(b_shape))\n",
    "# prediction\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    y_pred = tf.add(tf.matmul(X, W), b)\n",
    "# loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_sum(tf.pow(tf.subtract(y, y_pred), 2))\n",
    "# optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 76.32481384277344\n",
      "epoch 100, loss: 5.032845497131348\n",
      "epoch 200, loss: 2.500154495239258\n",
      "epoch 300, loss: 1.9693489074707031\n",
      "epoch 400, loss: 1.8021502494812012\n",
      "epoch 500, loss: 1.741830825805664\n",
      "epoch 600, loss: 1.7185707092285156\n",
      "epoch 700, loss: 1.7093147039413452\n",
      "epoch 800, loss: 1.705579400062561\n",
      "epoch 900, loss: 1.7040627002716064\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "file_writer_path = \"./graphs/linear-regression\"\n",
    "loss_history = []\n",
    "n_obs = X_train.shape[0]\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    train_writer = tf.summary.FileWriter(file_writer_path, tf.get_default_graph())\n",
    "    for i in range(epochs):\n",
    "        pos = 0\n",
    "        while pos < n_obs:\n",
    "            batch_X = X_train[pos:(pos + batch_size)]\n",
    "            batch_y = y_train[pos:(pos + batch_size)]\n",
    "            feed_dict = {\n",
    "                X: batch_X,\n",
    "                y: batch_y\n",
    "            }\n",
    "            _, loss_ = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "            pos += batch_size\n",
    "        loss_history.append(loss_)\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, loss: {}\".format(i, loss_))\n",
    "    w_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), loss_history)\n",
    "plt.title(\"Loss Summary\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532445963.4320564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_pred_before_inverse = X_test.dot(w_final) + b_final[0]\n",
    "y_pred = scalery.inverse_transform(y_pred_before_inverse)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.3, random_state=123)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
